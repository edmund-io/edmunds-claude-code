# AI CLI Orchestrator - Environment Configuration Template
# Copy this file to .env and fill in your API keys
#
# cp .env.example .env
# nano .env
#

# ========================================================================
# PROVIDER API KEYS
# ========================================================================

# Google Gemini (FREE 1M tokens/day - HIGHLY RECOMMENDED)
# Get key: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# OpenAI ($5 trial credits, expires in 3 months)
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic Claude ($5 trial credits, requires US phone)
# Get key: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# DeepSeek (1M tokens + $1 trial, then $0.27/$1.10 per 1M)
# Get key: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=

# Groq (FREE forever, 14.4K requests/day, 300+ tokens/sec)
# Get key: https://console.groq.com/keys
GROQ_API_KEY=

# xAI Grok (optional - no free tier as of 2025)
# Get key: https://console.x.ai/
XAI_API_KEY=

# ========================================================================
# SYSTEM CONFIGURATION
# ========================================================================

# Installation directory
AI_CLI_ORCHESTRATOR_DIR=$HOME/.ai-cli-orchestrator

# Logging level (debug, info, warn, error)
AI_CLI_ORCHESTRATOR_LOG_LEVEL=info

# Default provider (gemini, openai, anthropic, deepseek, groq, local)
AI_DEFAULT_PROVIDER=gemini

# Rate limiting safety margin (0.5 - 1.0, default 0.8 = 80% of limit)
AI_RATE_LIMIT_MARGIN=0.8

# ========================================================================
# QUOTA TRACKING (Optional)
# ========================================================================

# Enable quota tracking and logging
AI_QUOTA_TRACKING_ENABLED=true

# Quota log file
AI_QUOTA_LOG_FILE=$HOME/.ai-cli-orchestrator/logs/quota.log

# Alert when quota reaches threshold (0.0 - 1.0)
AI_QUOTA_ALERT_THRESHOLD=0.9

# ========================================================================
# PROVIDER-SPECIFIC SETTINGS
# ========================================================================

# Gemini settings
GEMINI_DEFAULT_MODEL=gemini-2.5-flash
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=2048

# OpenAI settings
OPENAI_DEFAULT_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2048

# Claude settings
ANTHROPIC_DEFAULT_MODEL=claude-3.5-sonnet
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=2048

# DeepSeek settings
DEEPSEEK_DEFAULT_MODEL=deepseek-v3
DEEPSEEK_TEMPERATURE=0.7
DEEPSEEK_MAX_TOKENS=2048

# Groq settings
GROQ_DEFAULT_MODEL=llama-3.3-70b-versatile
GROQ_TEMPERATURE=0.7
GROQ_MAX_TOKENS=2048

# ========================================================================
# ADVANCED SETTINGS
# ========================================================================

# Enable caching for repeated queries
AI_CACHING_ENABLED=true

# Cache directory
AI_CACHE_DIR=$HOME/.ai-cli-orchestrator/cache

# Cache TTL in seconds (default: 3600 = 1 hour)
AI_CACHE_TTL=3600

# Enable automatic fallback to backup providers
AI_AUTO_FALLBACK=true

# Fallback chain (comma-separated)
AI_FALLBACK_CHAIN=gemini,groq,local,deepseek,openai,anthropic

# ========================================================================
# DOCKER-SPECIFIC (if using Docker deployment)
# ========================================================================

# Docker image tag
DOCKER_IMAGE_TAG=latest

# Workspace mount path
WORKSPACE_PATH=./workspace

# ========================================================================
# NOTES
# ========================================================================

# Free Tier Recommendations:
# 1. Start with Gemini (1M tokens/day FREE)
# 2. Add Groq for speed-critical tasks (14.4K req/day FREE)
# 3. Install Ollama for 100% local/free inference (unlimited)
# 4. Use DeepSeek for cheap reasoning tasks after free tier ($0.27/$1.10)
# 5. Reserve OpenAI/Claude for premium quality tasks

# Cost Optimization:
# - Pure free tier: $0/month (Gemini + Groq + Ollama)
# - Hybrid: $10-20/month (free tier + DeepSeek for complex tasks)
# - Premium: $30-50/month (add Claude Code Pro for best coding)

# Expected Capacity at $0/month:
# - Gemini: 1M+ tokens/day
# - Groq: 14.4K requests/day, 300+ tokens/sec
# - Ollama: Unlimited (local hardware only)

# For more information, see:
# - QUICKSTART.md
# - AI_CLI_MASTER_RESEARCH_REPORT.md
# - FREE_TIER_QUOTA_MATRIX.md
